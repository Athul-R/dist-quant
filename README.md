# dist-quant
Distribution Aware Companding Quantization for transformers.

This is the repo for distribution aware companding quatization. 
The project report can be found [here](https://drive.google.com/file/d/1tnjG-KCm7NHFayHIuHcdyUgkk4Z_GNkd/view?usp=sharing).

In short we are building upon the Activating Aware Quantization ([AWQ](https://github.com/mit-han-lab/llm-awq)) and further using the weight distribution probabilities to quantize all the weights. 

The models we use are [Qwen3-1.7B](https://huggingface.co/Qwen/Qwen3-1.7B), [LLama 3.1 1B, 3B](https://www.llama.com/models/llama-3/) models.



